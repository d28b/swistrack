/** \file documentation.oxy
* \brief File Keeping non code related documentation
*/

/** \mainpage SwisTrack: Multi-Object Tracking - A Tool for Robotics and Biology
*
* For version changes, please consult changelog.txt
*
* \section intro Introduction
* This documentation is addressed to users of SwisTrack as well as developers that want to understand
* and eventually extend its current implementation.
* While this documentation explains usage and features of SwisTrack in detail, it also documents the 
* underlying source code and class structure. This is achieved by hyperlinking SwisTrack's functionality
* from the tutorial to the class documentation, allowing the developer to quickly gain an understanding of
* how the software is engineered, but without bothering the end-user too much with implementational issues.
*
* \section quick Quick-Start: First Tracking Trials
* Launching SwisTrack, the user is presented an empty window with the 'File' menu as only active item.
* Here, the user is able to create a new configuration or to load a previous session.<br>
* For a first trial, create a new configuration by clicking on 'New' in the 'File' menu.<br>
* This opens a dialog (MyNewCfgDialog) allowing for specifying a video file, a background image, and the number of objects 
* to track. For simple tracking, without calibration, you can ignore the other tabs in this dialog but you need to fill in
* the following information:
* 
* \subsection videofile Video File
* Obviously, you need to specify a video file containing the the data you want to analyze.
* 
* \subsection backgroundimage Background Image
* The way SwisTrack identifies objects of interest is by subtracting a static background image (taken prior to the
* experiment) from every video frame, leading to a difference image. In case of 'empty' video frames, this procedure 
* leads to zero valued (black) images. Objects that have not been present on the background image lead to pixel values 
* unequal zero. Here, the difference is the larger, the higher the contrast between the objects and the background. As 
* noise and shadows tend to have much lower contrast than 'real' objects, SwisTrack allows to set a threshold for the
* amplitude in the difference image (see ExperimentCfg::threshold).<br>
* <br>
* <b>Tip:</b> Consider, that differences in lighting conditions between background image and video file lead to very 
* strong differences that might shadow the presence of objects. Thus, make sure to take the background image immediately
* before tracking and try not to change lighting conditions during the video is taken (keep curtains closed, also consider
* reflections on bright cloths and apparel when approaching the arena). Hereby, it is not important, that the background
* is <i>clean</i>, but that the amount of <i>dirt</i> is not changing. Thus, successful tracking is also possible if there 
* are static artifacts, e.g. obstacles or shelters, in the arena. However, if they execeed the size of the objects you track,
* make sure they cannot move.
* 
* \subsubsection estimate Estimated Background
* A new feature since version 2.1.0 is the possiblitiy to generate the background image on the fly (choose "Estimate" in the New Experiment
* dialog). Background estimation is realized by an infinite response filter with parameter $\alpha$, and is given by<br>
* <br>
* $\hat{E}_{n+1}=(1-\alpha)\hat{E}_n+\alpha M<br>
* <br>
* with $E$ the estimated background and $M$ the current image. If $\alpha$ is choosen to small, the background won't adapt fast enough to changes.
* If $\alpha$ is choosen to high however, non-moving objects immediately become part of the background image and are thus no more detected.
*
* \subsection noofobjects Number of Objects
* SwisTrack is able to track objects even if their contours melt/overlie by exploiting knowledge of the
* number of objects. However, keep in mind that tracking does not start before all objects are separated in
* one frame. This implies that tracking won't start if you choose a number which is higher than the available 
* objects.<br>
* <br>
* <b>Tip: </b> If you are just interested in actually watching the video or using calibration features, set the
* number of objects to track to 'zero'.<br> 
*<br>
* After pressing 'Ok', you will observe that the menu items 'Control' and 'View' became active. Start tracking
* now by pressing 'Go' in the control menu. Ignore calibration at this point and answer the question to ignore calibration
* with 'Yes'. This launches a new thread that processes the video and calls MyFrame::otProcessData()
* for every frame, where data is written to disk and the screen is updated.<br>
* Now you can start playing with tracking and segmenter parameters.
* 
* \subsection sp Segmenter Parameters
* As a first step in tracking, the image has to be segmented and possible candidates to track have to be identified
* (Segmenter).
* Firstly, this is done using a threshold parameter (ExperimentCfg::threshold), defining the minimum contrast between 
* an object/noise and the background image in order for taking it into consideration as a possible candidate for tracking.
* Secondly, the user is able to specify the minimum area of an object (ExperimentCfg::minarea). Both parameters can be 
* changed in the segmenter panel (MySegmenterPanel), that can be enabled by toggeling 'Show Segmenter Panel' in the
* 'View' menu.<br>
* The segmenter panel also shows the binary image, where objects show as white dots on black ground (MySegmenterPanelCanvas). Changing the threshold
* parameter immediately changes their number and size.<br>
* <br>
* <b>Tip: </b>Experiment with this parameter by always starting with the threshold value. Depending on your lighting conditions
* you need different values until all objects show up as separated, white blobs. Now, you can adjust the minimum area (in 
* square pixels) slider to tell SwisTrack about the minimum size you allow an object of interest to be.
* 
* \subsection tp Tracking Parameters
* As soon as the video frame is segmented, possible candidates have to be associated with the trajectories of the tracked
* objects (Tracker). SwisTrack solves this task by choosing for every object the nearest possible candidate. However, it might be that two 
* objects' contours overlap, leading to no possible candidates in its neighborhood. In this case, noise is malicious; the
* trajectory that does not find any nearby object will choose any noise in the arena. This can be prevented by setting the
* -object specific- maxspeed parameter (ExperimentCfg::maxspeed). It limits which distance (in pixels) an object can move from one frame 
* to the other. Its value is dependent on the objects speed as well as on the frame rate of the video - lower frame rates lead
* to larger displacements. Change this parameter by enabling the tracker panel (MyTrackingPanel) in the 'View' menu.<br>
* <br>
* <b>Tip: </b>Experiment with this parameter by setting it to zero first, you will see that no objects will be tracked anymore.
* Then, set the maximum object speed to the highest value possible - you will see how the trajectories grab even remote moving
* objects.<Br><Br><br>
* <b>Tip: </b>The default parameters for Segmenter and Tracker might not be optimal for your particular setup. Try to find 
* parameters that lead to the best result and restart the tracking process. SwisTrack does not forget the parameters you chose!
* <img src="swistrack.png">
* \section calib Calibration 
* In order to gain tracking coordinates in world space and not only in image space, you need to supply SwisTrack with a calibration
* image showing a training pattern of known geometry. You can to this on the 'Advanced' tab in the new configuration dialog (File
* menu, MyNewCfgDialog). Please enter here the bitmap containing the calibration pattern as well as a background image without
* calibration pattern. Usually, this can be the same as the normal background image. However, if you are using static objects
* in your arena, as for instance shelters, that are not on the calibration image, finding the calibration target will not work. Pressing
* 'Ok' now and starting tracking with 'Go' from the control menu will now start the calibration wizard previous to tracking.
* 
* \subsection finding Identifiying the Arena
* First of all, the software will ask you to help it identify the arena within the background. 
* For that, you are provided with a slider bar and the current idea of SwisTrack where the arena is.<br>
* <img src="findthearena.png"><br>
* Try to move the slider to the left and right until the arena is clearly segmented (compare above Figure, center). 
* If the arena is too small, you usually need to move the slider to the left, if the arena is to big, move it to the right.
* If you are satisfied with your choice, proceed by clicking into the image.
*
* \subsection findingt Identifying the Calibration Target
* In order to help SwisTrack find the spots on the calibration target, you need now to proceed as with the background image by using the left slider, indicated by "Mask".
* Do so, until you achieve a similar result to below Figure, left.<br>
* <img src="findingthetarget.png"><br>
* Then, you can change the number of detected spots using the right slider. Do so, until all 69 spots are clearly 
* recognized (above Figure, right), which is indicated by white circles, and press any key when ready.
*
* \subsection takecalib Taking the calibration image
* For calculating the transformation from image space to world space (see the description of the Transformation class),
* a pattern of known dimensions has to be presented to the software. Such a pattern is shipped with SwisTrack as PDF 
* document. It has to be printed on A0 and must not be downscaled. The distances between the reference points are 
* hard-coded into the software and can not be changed.
* <br>
* For taking the calibration image, the calibration pattern has to be placed within the arena. The software is capable of 
* finding the offset between the center of the pattern and the center of the arena, thus roughly centering of the pattern 
* within the arena is sufficient. However, quality of the prediction increases with the accuracy of placement. It is 
* therefore suggested to align the center of the camera with the calibration pattern using a pendulum that extends from 
* the camera to the floor.<br>
* <br>
* <i>N.B.:</i> After the calibration image has been taken, the arena must not be moved anymore. 
* Any error introduced by shifting the arena is reflected as an offset in world space!
*
* \section mask Counting objects in different areas
* Since version 2.2.0 it is possible to supply a b&w image (the "mask" image), which allows to define regions of interest. Regions of interest are
* represented by a set of connected white pixels. In this regions, SwisTrack will count the number of objects that are present at every time step. 
* The number of regions you can specify is not limited, identified regions will be ennumerated and can be identified by their center and size that
* will be written to disk along with the tracking data (<i>xxx_mask.txt</i>).
*
* \section coverage Coverage Image
* For demonstration purposes, a coverage visualisation is part of SwisTrack since version 2.1.1. The coverage of the arena by any particles (not limited
* to identified objects) since the start of the experiment can be visualized from the 'View' menu, 'Show Coverage'.
* <img src="swistrack_coverage.png">
*
* \section loadnsave Loading and Saving Configurations
* For your convenience, you might want to save configurations in order not to reenter all parameters again if you need to start over.
* Note, that SwisTrack also keeps track of the parameters you choose for the Segmenter and Tracker.
*
* \section store Post-processing Tracking Data
* For SwisTrack store data to disk, you need to enter a filename in the 'Output' tab of the new configuration dialog.
* This will create two files, <i>xxx.txt</i> and <i>xxx_uncalib.txt</i> for calibrated data and raw data respectively, while mask data
* is stored in <i>xxx_mask.txt</i>
* If the calibration image is omitted, only uncalibrated data will be stored. 
*
* \subsection format Format of the Tracking Data
* The data is saved row-wise, one row for every frame. In the first column you find the frame number, the second column is
* the time (in seconds). Object trajectories are then stored as <i>(x,y)</i> and <i>(u,v)</i> pairs for calibrated and uncalibrated
* data respectively. Thus the number of columns per file is given by
* \f[2+n*2\f]
* with <i>n</i> the number of objects to track. 
*
* \section manual Manual Mode
* SwisTrack offers you to resolve collisions automatically (not very reliable) or asks you for your support in case of
* uncertainity. To enable this feature, check 'Manual Mode' in the 'Mode' menu. In manual mode, SwisTrack only shows the trajectories
* of the involved objects and asks you in the status bar to click on a certain object. 
*
* \section video Saving Video Files
* Since version 2.0.1, it is possible to save video segments for demo purposes. For that, select an output file in the "Tools" menu,
* which enables the switch to turn video storage on and off. Toggle this switch anytime during tracking. A window will appear,
* allowing you to choose from a set of codecs installed on your system. We recommend to use a MPEG4 codec as DivX or XVid. If you
* want the video to start a precise position use the pause function from the control menu.<br>
* A video frame will only be written if the screen gets updated, thus you are not able to reproduce pauses in the video - also
* video output will stop. Also, the frame rate of your video is given by your display speed (to be set in the toolbar).<br>
* <br>
* <b>Tip: </b>To create accelerated time videos, enable video storage in pause mode with the fastest display speed possible 
* (given by your input file). Then set the display speed to the lowest possible value (1Hz) and continue tracking. As the output
* video's framerate will be set to the maximum speed (say, 30Hz), but frames were just taken every 1 second, the video will be
* accelerated by factor 30!
*/
 