<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<html><head><meta http-equiv="Content-Type" content="text/html;charset=iso-8859-1">
<title>Swistrack Gui: SwisTrack: Multi-Object Tracking - A Tool for Robotics and Biology</title>
<link href="doxygen.css" rel="stylesheet" type="text/css">
</head><body>
<!-- Generated by Doxygen 1.4.2 -->
<div class="qindex"><a class="qindexHL" href="index.html">Main&nbsp;Page</a> | <a class="qindex" href="files.html">File&nbsp;List</a></div>
<h1>SwisTrack: Multi-Object Tracking - A Tool for Robotics and Biology </h1>
<p>
<h2><a class="anchor" name="intro">
Introduction</a></h2>
This documentation is addressed to users of SwisTrack as well as developers that want to understand and eventually extend its current implementation. While this documentation explains usage and features of SwisTrack in detail, it also documents the underlying source code and class structure. This is achieved by hyperlinking SwisTrack's functionality from the tutorial to the class documentation, allowing the developer to quickly gain an understanding of how the software is engineered, but without bothering the end-user too much with implementational issues.<h2><a class="anchor" name="quick">
Quick-Start: First Tracking Trials</a></h2>
Launching SwisTrack, the user is presented an empty window with the 'File' menu as only active item. Here, the user is able to create a new configuration or to load a previous session.<br>
 For a first trial, create a new configuration by clicking on 'New' in the 'File' menu.<br>
 This opens a dialog (MyNewCfgDialog) allowing for specifying a video file, a background image, and the number of objects to track. For simple tracking, without calibration, you can ignore the other tabs in this dialog but you need to fill in the following information:<h3><a class="anchor" name="videofile">
Video File</a></h3>
Obviously, you need to specify a video file containing the the data you want to analyze.<h3><a class="anchor" name="backgroundimage">
Background Image</a></h3>
The way SwisTrack identifies objects of interest is by subtracting a static background image (taken prior to the experiment) from every video frame, leading to a difference image. In case of 'empty' video frames, this procedure leads to zero valued (black) images. Objects that have not been present on the background image lead to pixel values unequal zero. Here, the difference is the larger, the higher the contrast between the objects and the background. As noise and shadows tend to have much lower contrast than 'real' objects, SwisTrack allows to set a threshold for the amplitude in the difference image (see ExperimentCfg::threshold).<br>
 <br>
 <b>Tip:</b> Consider, that differences in lighting conditions between background image and video file lead to very strong differences that might shadow the presence of objects. Thus, make sure to take the background image immediately before tracking and try not to change lighting conditions during the video is taken (keep curtains closed, also consider reflections on bright cloths and apparel when approaching the arena). Hereby, it is not important, that the background is <em>clean</em>, but that the amount of <em>dirt</em> is not changing. Thus, successful tracking is also possible if there are static artifacts, e.g. obstacles or shelters, in the arena. However, if they execeed the size of the objects you track, make sure they cannot move.<h4><a class="anchor" name="estimate">
Estimated Background</a></h4>
A new feature since version 2.1.0 is the possiblitiy to generate the background image on the fly (choose "Estimate" in the New Experiment dialog). Background estimation is realized by an infinite response filter with parameter $$, and is given by<br>
 <br>
 ${E}_{n+1}=(1-){E}_n+ M<br>
 <br>
 with $E$ the estimated background and $M$ the current image. If $$ is choosen to small, the background won't adapt fast enough to changes. If $$ is choosen to high however, non-moving objects immediately become part of the background image and are thus no more detected.<h3><a class="anchor" name="noofobjects">
Number of Objects</a></h3>
SwisTrack is able to track objects even if their contours melt/overlie by exploiting knowledge of the number of objects. However, keep in mind that tracking does not start before all objects are separated in one frame. This implies that tracking won't start if you choose a number which is higher than the available objects.<br>
 <br>
 <b>Tip: </b> If you are just interested in actually watching the video or using calibration features, set the number of objects to track to 'zero'.<br>
 <br>
 After pressing 'Ok', you will observe that the menu items 'Control' and 'View' became active. Start tracking now by pressing 'Go' in the control menu. Ignore calibration at this point and answer the question to ignore calibration with 'Yes'. This launches a new thread that processes the video and calls MyFrame::otProcessData() for every frame, where data is written to disk and the screen is updated.<br>
 Now you can start playing with tracking and segmenter parameters.<h3><a class="anchor" name="sp">
Segmenter Parameters</a></h3>
As a first step in tracking, the image has to be segmented and possible candidates to track have to be identified (Segmenter). Firstly, this is done using a threshold parameter (ExperimentCfg::threshold), defining the minimum contrast between an object/noise and the background image in order for taking it into consideration as a possible candidate for tracking. Secondly, the user is able to specify the minimum area of an object (ExperimentCfg::minarea). Both parameters can be changed in the segmenter panel (MySegmenterPanel), that can be enabled by toggeling 'Show Segmenter Panel' in the 'View' menu.<br>
 The segmenter panel also shows the binary image, where objects show as white dots on black ground (MySegmenterPanelCanvas). Changing the threshold parameter immediately changes their number and size.<br>
 <br>
 <b>Tip: </b>Experiment with this parameter by always starting with the threshold value. Depending on your lighting conditions you need different values until all objects show up as separated, white blobs. Now, you can adjust the minimum area (in square pixels) slider to tell SwisTrack about the minimum size you allow an object of interest to be.<h3><a class="anchor" name="tp">
Tracking Parameters</a></h3>
As soon as the video frame is segmented, possible candidates have to be associated with the trajectories of the tracked objects (Tracker). SwisTrack solves this task by choosing for every object the nearest possible candidate. However, it might be that two objects' contours overlap, leading to no possible candidates in its neighborhood. In this case, noise is malicious; the trajectory that does not find any nearby object will choose any noise in the arena. This can be prevented by setting the -object specific- maxspeed parameter (ExperimentCfg::maxspeed). It limits which distance (in pixels) an object can move from one frame to the other. Its value is dependent on the objects speed as well as on the frame rate of the video - lower frame rates lead to larger displacements. Change this parameter by enabling the tracker panel (MyTrackingPanel) in the 'View' menu.<br>
 <br>
 <b>Tip: </b>Experiment with this parameter by setting it to zero first, you will see that no objects will be tracked anymore. Then, set the maximum object speed to the highest value possible - you will see how the trajectories grab even remote moving objects.<br>
<br>
<br>
 <b>Tip: </b>The default parameters for Segmenter and Tracker might not be optimal for your particular setup. Try to find parameters that lead to the best result and restart the tracking process. SwisTrack does not forget the parameters you chose! <div align="center">
<img src="swistrack.png" alt="swistrack.png">
</div>
 <h2><a class="anchor" name="calib">
Calibration</a></h2>
In order to gain tracking coordinates in world space and not only in image space, you need to supply SwisTrack with a calibration image showing a training pattern of known geometry. You can to this on the 'Advanced' tab in the new configuration dialog (File menu, MyNewCfgDialog). Please enter here the bitmap containing the calibration pattern as well as a background image without calibration pattern. Usually, this can be the same as the normal background image. However, if you are using static objects in your arena, as for instance shelters, that are not on the calibration image, finding the calibration target will not work. Pressing 'Ok' now and starting tracking with 'Go' from the control menu will now start the calibration wizard previous to tracking.<h3><a class="anchor" name="finding">
Identifiying the Arena</a></h3>
First of all, the software will ask you to help it identify the arena within the background. For that, you are provided with a slider bar and the current idea of SwisTrack where the arena is.<br>
 <div align="center">
<img src="findthearena.png" alt="findthearena.png">
</div>
<br>
 Try to move the slider to the left and right until the arena is clearly segmented (compare above Figure, center). If the arena is too small, you usually need to move the slider to the left, if the arena is to big, move it to the right. If you are satisfied with your choice, proceed by clicking into the image.<h3><a class="anchor" name="findingt">
Identifying the Calibration Target</a></h3>
In order to help SwisTrack find the spots on the calibration target, you need now to proceed as with the background image by using the left slider, indicated by "Mask". Do so, until you achieve a similar result to below Figure, left.<br>
 <div align="center">
<img src="findingthetarget.png" alt="findingthetarget.png">
</div>
<br>
 Then, you can change the number of detected spots using the right slider. Do so, until all 69 spots are clearly recognized (above Figure, right), which is indicated by white circles, and press any key when ready.<h3><a class="anchor" name="takecalib">
Taking the calibration image</a></h3>
For calculating the transformation from image space to world space (see the description of the Transformation class), a pattern of known dimensions has to be presented to the software. Such a pattern is shipped with SwisTrack as PDF document. It has to be printed on A0 and must not be downscaled. The distances between the reference points are hard-coded into the software and can not be changed. <br>
 For taking the calibration image, the calibration pattern has to be placed within the arena. The software is capable of finding the offset between the center of the pattern and the center of the arena, thus roughly centering of the pattern within the arena is sufficient. However, quality of the prediction increases with the accuracy of placement. It is therefore suggested to align the center of the camera with the calibration pattern using a pendulum that extends from the camera to the floor.<br>
 <br>
 <em>N.B.:</em> After the calibration image has been taken, the arena must not be moved anymore. Any error introduced by shifting the arena is reflected as an offset in world space!<h2><a class="anchor" name="mask">
Counting objects in different areas</a></h2>
Since version 2.2.0 it is possible to supply a b&amp;w image (the "mask" image), which allows to define regions of interest. Regions of interest are represented by a set of connected white pixels. In this regions, SwisTrack will count the number of objects that are present at every time step. The number of regions you can specify is not limited, identified regions will be ennumerated and can be identified by their center and size that will be written to disk along with the tracking data (<em>xxx_mask.txt</em>).<h2><a class="anchor" name="coverage">
Coverage Image</a></h2>
For demonstration purposes, a coverage visualisation is part of SwisTrack since version 2.1.1. The coverage of the arena by any particles (not limited to identified objects) since the start of the experiment can be visualized from the 'View' menu, 'Show Coverage'. <div align="center">
<img src="swistrack_coverage.png" alt="swistrack_coverage.png">
</div>
<h2><a class="anchor" name="loadnsave">
Loading and Saving Configurations</a></h2>
For your convenience, you might want to save configurations in order not to reenter all parameters again if you need to start over. Note, that SwisTrack also keeps track of the parameters you choose for the Segmenter and Tracker.<h2><a class="anchor" name="store">
Post-processing Tracking Data</a></h2>
For SwisTrack store data to disk, you need to enter a filename in the 'Output' tab of the new configuration dialog. This will create two files, <em>xxx.txt</em> and <em>xxx_uncalib.txt</em> for calibrated data and raw data respectively, while mask data is stored in <em>xxx_mask.txt</em> If the calibration image is omitted, only uncalibrated data will be stored.<h3><a class="anchor" name="format">
Format of the Tracking Data</a></h3>
The data is saved row-wise, one row for every frame. In the first column you find the frame number, the second column is the time (in seconds). Object trajectories are then stored as <em>(x,y)</em> and <em>(u,v)</em> pairs for calibrated and uncalibrated data respectively. Thus the number of columns per file is given by <p class="formulaDsp">
<img class="formulaDsp" alt="\[2+n*2\]" src="form_0.png">
<p>
 with <em>n</em> the number of objects to track.<h2><a class="anchor" name="manual">
Manual Mode</a></h2>
SwisTrack offers you to resolve collisions automatically (not very reliable) or asks you for your support in case of uncertainity. To enable this feature, check 'Manual Mode' in the 'Mode' menu. In manual mode, SwisTrack only shows the trajectories of the involved objects and asks you in the status bar to click on a certain object.<h2><a class="anchor" name="video">
Saving Video Files</a></h2>
Since version 2.0.1, it is possible to save video segments for demo purposes. For that, select an output file in the "Tools" menu, which enables the switch to turn video storage on and off. Toggle this switch anytime during tracking. A window will appear, allowing you to choose from a set of codecs installed on your system. We recommend to use a MPEG4 codec as DivX or XVid. If you want the video to start a precise position use the pause function from the control menu.<br>
 A video frame will only be written if the screen gets updated, thus you are not able to reproduce pauses in the video - also video output will stop. Also, the frame rate of your video is given by your display speed (to be set in the toolbar).<br>
 <br>
 <b>Tip: </b>To create accelerated time videos, enable video storage in pause mode with the fastest display speed possible (given by your input file). Then set the display speed to the lowest possible value (1Hz) and continue tracking. As the output video's framerate will be set to the maximum speed (say, 30Hz), but frames were just taken every 1 second, the video will be accelerated by factor 30! <hr size="1"><address style="align: right;"><small>Generated on Fri Apr 15 12:39:28 2005 for Swistrack Gui by&nbsp;
<a href="http://www.doxygen.org/index.html">
<img src="doxygen.png" alt="doxygen" align="middle" border="0"></a> 1.4.2 </small></address>
</body>
</html>
